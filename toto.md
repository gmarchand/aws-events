| url | title | description |
|-----|-----|-----|
| https://www.youtube.com/watch?v=FYfXj_rcVzs | AWS re:Invent 2023 - Predictive maintenance at scale: KAES’s journey with Amazon Monitron (AIM216) | Unexpected equipment failure is costly for industrial facilities. But scheduling maintenance too frequently wastes resources. In this session, hear from Koch 
Ag & Energy Solutions (KAES) on how they use Amazon Monitron to implement predictive maintenance across their industrial machinery. Learn how, with Amazon Monitron’s wireless sensors and machine learning, you can reduce unplanned downtime and transform maintenance operations to be data-driven and 
proactive.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.ly/2O3zS75More AWS events videos: |
| https://www.youtube.com/watch?v=cTyXDhiltXw | AWS re:Invent 2023 - Accelerate FM development with Amazon SageMaker JumpStart (AIM328) | Generative AI is empowering organizations to innovate faster to reinvent customer experiences and applications. But how can you ensure flexibility and control within 
your organization for generative AI application development? Amazon SageMaker provides managed infrastructure and tools to accelerate scalable, reliable, and secure foundation model (FM) development. In this session, dive into how Amazon SageMaker JumpStart makes it easy for ML practitioners to access 
FMs—including the best-performing publicly available FMs. Then see how you can analyze, evaluate, test, retrain, and deploy FMs usi |
| https://www.youtube.com/watch?v=jlqgGkh1wzY | AWS re:Invent 2023 - Prompt engineering best practices for LLMs on Amazon Bedrock (AIM377) | Prompt engineering is the process of guiding large language models (LLMs) to produce desired outputs. In this session, get an overview of prompt engineering best 
practices and learn how to choose the most appropriate formats, phrases, words, and symbols to get the most out of generative AI solutions while improving accuracy and performance. This session uses the Claude 2 LLM as an example of how prompt engineering helps to solve complex customer use cases. Also 
learn how prompts can be integrated with your architecture and how to use API parameters for tuning the model parameters using Amazon  |
| https://www.youtube.com/watch?v=jzIZcgaTruA | AWS re:Invent 2023 - Build your first generative AI application with Amazon Bedrock (AIM218) | We are truly at an exciting inflection point in the widespread adoption of ML with the growth of generative AI applications. In this session, learn how to build 
your first generative AI application with key services such as Amazon Bedrock. Get hints and tips for getting started fast, and see example reference architectures for common use cases built with AWS AI and ML such as self-service customer support, text analysis, report generation, post-call analysis, and 
forecasting trends.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.ly/2O3zS75Mo |
| https://www.youtube.com/watch?v=3BCa37587A0 | AWS re:Invent 2023 - Principal Financial enhances CX using call analytics and generative AI (AIM223) | With tens of thousands of calls a day, Principal Financial Group continually improves its customer experience. In this session, learn how Principal 
implemented Amazon Transcribe Call Analytics with their Genesys contact center. Principal shares how they envision integrating generative AI powered by Amazon Bedrock with their proprietary solutions. See demos on how to capture insights such as sentiment analysis, call handle time, and call intent to gain
customer insights and deliver a personalized and seamless customer experience. Finally, learn how you can supercharge your existing customer ser |
| https://www.youtube.com/watch?v=Nhl4JlQjc7U | AWS re:Invent 2023 - Enable generative AI trust and safety with Amazon Comprehend (AIM214) | Generative AI is transforming the world around us at a rapid pace, but with its immense potential comes great responsibility to maintain trust and safety. In this 
session, learn how you can develop and adopt AI solutions that are free from unintended harm or deception. Learn how a customer is using Amazon Comprehend to build systems that prevent malicious use and allow for transparency and oversight of generative AI. Hear from experts who can demonstrate how to put 
trust and safety guardrails in place and help you realize the full potential of generative AI to innovate and accelerate business  |
| https://www.youtube.com/watch?v=nDoojNaRhPE | AWS re:Invent 2023 - Jupyter AI: Open source brings LLMs to your notebooks (OPN203) | At AWS, our developers built Jupyter AI, an open source project to connect JupyterLab with generative AI large language models (LLMs) like Amazon Titan and OpenAI’s 
gpt-3.5-turbo (used in ChatGPT). In this session, explore how you can use the power of these models to become more productive. Learn from several use cases, including code refactoring, debugging, code explanation, and answering common questions, about how Jupyter AI can answer questions based on user 
input, help explain and fix code errors, and learn from and answer questions about local data files. Announced at JupyterCon 2023, Ju |
| https://www.youtube.com/watch?v=xxKGNhNkSzI | AWS re:Invent 2023 - Boost agent productivity with real-time transcription and insights (AIM224) | In this session, learn how to use AWS Contact Center Intelligence (CCI) solutions to unlock real-time transcription, conversational analytics, and agent 
recommendations. By implementing CCI solutions, you can quickly and accurately measure call sentiment and insights, build more personalized engagement strategies, and suggest the next best action to agents at scale. Additionally, learn how to augment CCI with generative AI capabilities such as Q&A, call 
summarization, and analytics to improve productivity and upgrade customer experience.Learn more about AWS re:Invent at https://go.aws/46iuzG |
| https://www.youtube.com/watch?v=b3Swj1hc5rY | AWS re:Invent 2023 - Enhance your document workflows with generative AI (AIM213) | Data classification, extraction, and analysis can be challenging for organizations that deal with volumes of documents. Traditional document processing solutions are manual, 
expensive, error-prone, and difficult to scale. AWS intelligent document processing (IDP) uses industry-leading machine learning (ML) technology to quickly and accurately process data from any document or image. Generative AI complements Amazon Textract to augment your IDP workflows with additional 
capabilities. In this session, hear a case study of Centene, which provides access to high-quality healthcare, innovative prog |
| https://www.youtube.com/watch?v=qwwLhbwS-rs | AWS re:Invent 2023 - Drive personalized CX using generative AI and Amazon Personalize (AIM225) | Delivering the best experience is critical to capture and retain customers today. With generative AI, it is possible to hyper-personalize targeted recommendations
for shopping and streaming. While standard taglines like “People who bought this also bought . . .” or “Because you watched . . .” entice some, they don’t fully address individual interests. Companies must find ways to dynamically generate compelling, highly customized content. Amazon Personalize delivers 
capabilities powered by ML and generative AI to help brands create meaningful experiences. Join this session to hear from powerhou |
| https://www.youtube.com/watch?v=Cwo83c4xvPQ | AWS re:Invent 2023 - Omics innovation with AWS HealthOmics: Amgen’s path to faster results (AIM215) | Omics data holds great promise for improving health outcomes and accelerating scientific discovery, but analyzing large, complex genomic and multiomics 
datasets presents challenges. Storing, accessing, and deriving understanding from these data requires specialized tools. Learn how Amgen, a leading biopharma company, overcomes these hurdles using AWS HealthOmics, a purpose-built genomics cloud service, to transform different types of omics data into 
insights. Hear how Amgen uses the secure storage and scalable workflows of HealthOmics to efficiently generate insights from high-volume omics dat |
| https://www.youtube.com/watch?v=ibq8redraiU | AWS re:Invent 2023 - Augment creative thinking & boost productivity with AWS generative AI (AIM211) | Marketing and sales professionals face ever-growing challenges capturing consumer and customer attention in a highly competitive landscape. Organizations 
implement generative AI to automate repetitive tasks, freeing time to create more engaging narratives and meet more customers. This session explores generative AI’s transformative creativity augmentation and productivity-boosting capabilities for marketing and sales teams. See how generative AI helps 
marketing teams generate creative content and helps sales teams automate and personalize communications and enablement assets. Also hear testimo |
| https://www.youtube.com/watch?v=QoaFYmpXvak | AWS re:Invent 2023 - Explore text-generation FMs for top use cases with Amazon Bedrock (AIM333) | Foundation models (FMs) can be used for natural language processing tasks such as summarization, text generation, classification, open-ended Q&A, and information
extraction. With Amazon Bedrock, you can choose powerful FMs from AI21 Labs, Anthropic, and Cohere to find the right FM for your use case such as the Jurassic-2, Claude, and Command families of text-generation FMs. Join this session to learn which FM is best suited for your use case.Learn more about AWS 
re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.ly/2O3zS75More AWS events videos: http://bit.ly/316g9 |
| https://www.youtube.com/watch?v=9X2oDkOBYyA | AWS re:Invent 2023 - Accelerate foundation model evaluation with Amazon SageMaker Clarify (AIM367) | Amazon SageMaker Clarify helps you evaluate which FM generates the most accurate and responsible content for your use case. Use this new capability during 
model selection and customization workflows to ensure you have the best FM based on criteria such as accuracy, robustness, toxicity, and bias. For aspects such as creativity, style, or tone that require human judgment, you can use embedded human-in-the-loop capabilities to set up human reviews. Join us to 
learn about one of the most comprehensive and easiest ways to evaluate FMs so that you can adopt FMs to build mission-critical generative  |
| https://www.youtube.com/watch?v=eMr3IG3u6Vg | AWS re:Invent 2023 - Atria Senior Living is empowering older adults with the power of voice (ALX101) | In this session, learn how Atria Senior Living is collaborating with Amazon Alexa, AWS, and Aiva Health to develop customized, industry-leading Alexa 
experiences tailored to the unique needs of older adults in senior living communities. This session follows the Atria journey from their initial vision for an integrated community assistant to being a first adopter of digital signage with Amazon Echo devices in their properties, connecting residents and 
loved ones with WebRTC-powered Alexa, providing application communications backed by AWS, and deploying Echo devices at scale.Learn more about  |
| https://www.youtube.com/watch?v=uRI0dllESko | AWS re:Invent 2023 - Responsible AI in the generative era: Science and practice (AIM220) | The rapid growth of generative AI brings promising innovation and at the same time raises new challenges around its safe and responsible development and use. These 
challenges include some that were common before generative AI, such as bias and explainability, and new ones unique to generative models, including hallucination, toxicity, and intellectual property protection. In this session, get an overview of the challenges presented by generative AI, survey the 
emerging science around them, and discuss the hands-on, responsible AI work being conducted on AWS.Learn more about AWS re:Invent at  |
| https://www.youtube.com/watch?v=b5k0YkQwV90 | AWS re:Invent 2023 - Choosing the right generative AI use case (AIM212) | Generative AI represents an exciting new capability for all organizations, but the most impactful applications are those focused on tangible business value, not just technological 
novelty. In this session, get an overview of the most impactful current use cases of generative AI across business functions and key industries. Learn best practices for generative AI implementation that uplifts processes, empowers people, and shifts mindsets to unlock demonstrable business value.Learn 
more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.ly/2O3zS75More AWS ev |
| https://www.youtube.com/watch?v=wM0iSWAzyhI | AWS re:Invent 2023 - Large model training on AWS Deep Learning AMIs & PyTorch, ft. Pinterest -AIM326 | Join this session for a deep dive into the infrastructure used to train large models at Pinterest. It covers training hardware, compute orchestration, and 
ML application development SDKs as well as how infrastructure choices speed up development and improve model training efficiency. See how Pinterest integrates AWS services like Amazon EC2 UltraClusters and AWS Deep Learning AMIs to reduce the total cost of ownership for ML infrastructure.Learn more about 
AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.ly/2O3zS75More AWS events videos: http://bit.ly/316g9t4 |
| https://www.youtube.com/watch?v=T2c7RaWVBJg | AWS re:Invent 2023 - Deploy FMs on Amazon SageMaker for price performance (AIM330) | As you advance in your journey from evaluating foundation models (FMs) to building generative AI applications at scale, you need services to deploy these models at the best 
price performance. From low latency (a few milliseconds) and high throughput (millions of transactions per second) use cases for chatbots to long-running inference use cases for natural language processing, you can use Amazon SageMaker for virtually all your inference needs. In this session, take a deep 
dive tour of features that make SageMaker a great choice for deploying FMs for inference and learn how you can benefit fro |
| https://www.youtube.com/watch?v=VVz6tNUYInY | AWS re:Invent 2023 - Bring the power of generative AI to your employees with Amazon Q (AIM240) | Are you struggling to make generative AI available to your employees in a secure, quick way? This session demonstrates how Amazon Q can provide secure, quick 
access to the power of generative AI for your employees. Amazon Q understands natural language, provides contextual answers using connected data sources, summarizes documents, generates content, and automates actions across enterprise applications and document repositories. Learn how to implement Amazon Q 
with enterprise-grade access controls that help ensure that users get appropriate responses based on their permissions.Learn more abo |
| https://www.youtube.com/watch?v=mFbt7TfoI_o | AWS re:Invent 2023 - Taking BMW Group’s in-vehicle voice experience from idea to reality (ALX201) | In this session, learn how BMW Group is building a unique, next-generation AI voice assistant that takes the BMW and MINI in-vehicle voice experience to the 
next level. With or without an internet connection, AWS expands the BMW cloud environment by deploying an embedded, neural text-to-speech SDK that provides a highly natural, uninterrupted voice experience. This session explores BMW Group’s vision of in-car voice assistants. Learn from their insights into 
the entire product development journey from ideation, distilling brand personality traits, recruiting voice actors, and training large mu |
| https://www.youtube.com/watch?v=GBIkeMemh2E | AWS re:Invent 2023 - Democratize ML with no code/low code using Amazon SageMaker Canvas (AIM217) | Machine learning (ML) can solve business problems that help organizations achieve better outcomes. But, how do you take ML beyond technical users to implement 
it throughout your organization? In this session, learn how you can use Amazon SageMaker Canvas to complete the ML lifecycle from preparing data and creating models to generating predictions, without writing a single line of code. With SageMaker Canvas, you can utilize ready-to-use models or create your 
own models to get insights from your data and ML models. Join us in the journey to democratize ML across your organization and achieve b |
| https://www.youtube.com/watch?v=S0rltBHGMjw | AWS re:Invent 2023 - How Fetch built world-class ML models to power their business (SEG301) | Fetch, a leading shopping loyalty app, moved from buying ML models to building their own. In 18 months, they built eight models that scan, process, eliminate fraud, 
personalize, and forecast. In this session, learn how Fetch built their team, implemented Amazon SageMaker as the ML platform, and trains and deploys critical models. Since adopting SageMaker for ML work, Fetch has improved the accuracy of its document-understanding model from 30% to 90% and has reduced 
latency for its users by 50%.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.l |
| https://www.youtube.com/watch?v=6xENDvgnMCs | AWS re:Invent 2023 - Scaling FM inference to hundreds of models with Amazon SageMaker (AIM327) | Companies need robust and cost-effective solutions to deploy foundation models (FMs) at scale. Additionally, SaaS providers need scalable and cost-effective ways 
to serve hundreds of models to their customers. This session explores how to use Amazon SageMaker to roll out hundreds of FMs cost effectively at scale. Get a detailed overview of deployment strategies to support large-scale generative AI inferencing for SaaS, and learn how to architect solutions that 
maximize scaling capabilities for performance and cost.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS |
| https://www.youtube.com/watch?v=N0tlOXZwrSs | AWS re:Invent 2023 - Use RAG to improve responses in generative AI applications (AIM336) | Your generative AI applications can deliver better responses by incorporating organization-specific data through a technique known as Retrieval Augmented Generation 
(RAG). However, implementing RAG requires time to configure connections to data sources, manage data ingestion workflows, and write custom code to manage the interactions between the foundation model (FM) and the data sources. Join this session to learn how to make the process much easier using Amazon 
Bedrock. Based on the user prompt, Amazon Bedrock automatically identifies data sources, retrieves the relevant information, and add |
| https://www.youtube.com/watch?v=YY9N7sDoP30 | AWS re:Invent 2023 - Customize FMs for generative AI applications with Amazon Bedrock (AIM247) | Foundation models (FMs), like LLMs, have shown impressive capabilities across many natural language tasks. However, directly utilizing these models for 
applications can present challenges. In this session, explore and compare methods for effectively adapting foundation models for your applications. Learn how to evaluate prompt engineering, which reformulates the task into natural language, and fine-tuning, which updates the models' parameters on new tasks
and use cases. Explore the trade-offs between usability and resource requirements for each method. Learn how to productively use the capabil |
| https://www.youtube.com/watch?v=WsOH3NS_1EQ | AWS re:Invent 2023 - Amazon Lex reshapes CX with conversational workflows and generative AI (AIM222) | Customers expect personalized and immediate responses from chat- and voice-based virtual agents. Learn how you can use Amazon Lex powered by generative AI 
to deliver self-service customer experiences. Understand how a fully integrated platform with Amazon Lex and Amazon Connect can help create personalized omnichannel workflows for employees and customers.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: 
http://bit.ly/2O3zS75More AWS events videos: http://bit.ly/316g9t4ABOUT AWSAmazon Web Services (AWS) hosts events, both online and in-person, bringin |
| https://www.youtube.com/watch?v=SdbfLgqc7is | AWS re:Invent 2023 - Explore Amazon Titan for language tasks (AIM331) | Amazon Titan foundation models (FMs) are pretrained on large datasets, making them powerful, general-purpose models. You can use them as is or privately customize them with your own data.
Join this session to learn how to use Amazon Titan Text for creating copy for blog posts and web pages, classifying articles into categories, open-ended Q&A, and information extraction.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.ly/2O3zS75More AWS events 
videos: http://bit.ly/316g9t4ABOUT AWSAmazon Web Services (AWS) hosts events, both online and in- |
| https://www.youtube.com/watch?v=ZW_z5o_gWhQ | AWS re:Invent 2023 - Explore image generation and search with FMs on Amazon Bedrock (AIM332) | Foundation models (FMs) understand multiple forms of input, such as images and texts. Join this session to learn how to build transformational experiences using 
images in Amazon Bedrock.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS videos: http://bit.ly/2O3zS75More AWS events videos: http://bit.ly/316g9t4ABOUT AWSAmazon Web Services (AWS) hosts events, both online and in-person, bringing the cloud computing community together to 
connect, collaborate, and learn from AWS experts.AWS is the world's most comprehensive and broadly adopted cloud platform, off |
| https://www.youtube.com/watch?v=9T775vCL-ak | AWS re:Invent 2023 - Improve FMs with Amazon SageMaker human-in-the-loop capabilities (AIM334) | Amazon SageMaker Ground Truth offers a set of human-in-the-loop capabilities for machine learning, allowing you to harness the power of human feedback across the 
ML lifecycle. In this session, learn how AWS uses human input to help you create high-quality training datasets for your generative AI applications (through supervised fine tuning and reinforcement learning with human feedback) and customize foundation models (FMs) on specific tasks or with company- and 
domain-specific data. Join this session to see real-world examples and demos.Learn more about AWS re:Invent at https://go.aws/46iuz |
| https://www.youtube.com/watch?v=JNZPW82uv7w | AWS re:Invent 2023 - Simplify generative AI app development with Agents for Amazon Bedrock (AIM353) | FMs effectively conduct conversations, create content, and drive productivity, but they can deliver more value if they’re equipped to transact with company 
systems to complete multi-step tasks. Fully managed Agents for Amazon Bedrock enables generative AI applications to help perform multi-step tasks across company systems and data sources, saving you from engineering prompts, training models, or manually connecting systems. Agents can plan and perform most 
tasks, from answering customer questions about product availability to checking inventory. Learn how to create agents by securely orchestr |
| https://www.youtube.com/watch?v=i2-M7x9dJXQ | AWS re:Invent 2023 - Train and tune state-of-the-art ML models on Amazon SageMaker (AIM335) | Train machine learning (ML) models faster on Amazon SageMaker with state-of-the-art training tools and the highest-performing ML compute infrastructure currently 
available. SageMaker interactive debugging and profiling tools can uncover complex model behaviors and dissect hardware utilization in near real time. You can also optimize distributed training jobs with the fastest and easiest methods for training large deep learning models and datasets. Join this session
to learn about new features that enable large-scale and cost-effective model training. Get prescriptive guidance across the entire |
| https://www.youtube.com/watch?v=KaBlf6CyoIk | AWS re:Invent 2023 - [LAUNCH] AWS Clean Rooms ML and AWS Clean Rooms Differential Privacy (AIM241) | AWS Clean Rooms helps organizations create clean rooms in minutes and collaborate with their partners without sharing underlying data. In this session, learn 
about AWS Clean Rooms ML, a new capability that helps companies apply privacy-preserving machine learning on their collective datasets to generate look-alike user segments without revealing raw data. Also explore AWS Clean Rooms Differential Privacy, a new feature that helps organizations generate insights
while protecting individual-level data. Hear from Tia White, General Manager of AI/ML at AWS, and an AWS customer on how these capabil |
| https://www.youtube.com/watch?v=vleGSQ_mIvc | AWS re:Invent 2023 - Accelerate generative AI application development with Amazon Bedrock (AIM337) | Generative AI has the potential to transform how companies build applications and engage customers by enabling more intuitive, conversational experiences. In 
this session, learn how to utilize Amazon Bedrock’s serverless experience to quickly build and scale generative AI applications with a choice of leading foundation models, while maintaining security and privacy. See how you can privately customize models with your own data to deliver differentiated 
experiences to your customers. See a demo of the end-to-end developer experience and the broad capabilities of Amazon Bedrock.Learn more abo |
| https://www.youtube.com/watch?v=-osfvAqydt0 | AWS re:Invent 2023 - Build responsible AI applications with Guardrails for Amazon Bedrock (AIM361) | Guardrails for Amazon Bedrock help organizations manage end-user experiences based on their application-specific requirements and responsible AI policies. You
can deliver consistently safe user experiences through generative AI applications, no matter the underlying FM. Learn how this new capability gives you the ability to define custom policies and manage interactions between users and foundation models (FMs) by filtering out disallowed topics and harmful 
content. Finally, see demos on how to create and apply custom tailored guardrails with FMs and Agents for Amazon Bedrock to implement resp |
| https://www.youtube.com/watch?v=1vlcD07bMlA | AWS re:Invent 2023 - [LAUNCH] Introducing Amazon SageMaker HyperPod (AIM362) | Amazon SageMaker HyperPod is purpose-built to accelerate foundation model (FM) training. Join this session to learn how to train FMs for weeks and months without disruption with 
Amazon SageMaker HyperPod. Discover how it continuously monitors cluster health and repairs and replaces faulty nodes on the fly to automatically resume training without losing progress. Learn about how it is preconfigured with SageMaker distributed training libraries that make it possible for you to 
improve FM training performance by making it easy to split training data and FMs into smaller chunks and process them in |
| https://www.youtube.com/watch?v=BkBD9JtRR1U | AWS re:Invent 2023 - New LLM capabilities in Amazon SageMaker Canvas, with Bain & Company (AIM363) | Learn to use the no-code Amazon SageMaker experience to build and use large language models (LLMs). See how to complete the entire ML lifecycle, including 
data exploration and preparation, using a new LLM-powered natural language interface, model building, and deployment without any code. Dive deep into new LLM capabilities, including how to compare outputs from multiple FMs and select the best FM to perform business analysis. Finally, Bain & Company shares 
how they are using SageMaker Canvas for their use cases.Learn more about AWS re:Invent at https://go.aws/46iuzGv.Subscribe:More AWS v |
| https://www.youtube.com/watch?v=AEK1kVZMIvM | AWS re:Invent 2023 - Evaluate and select the best FM for your use case in Amazon Bedrock (AIM373) | Today, organizations have a wide range of FM options to power their generative AI applications. To achieve the right balance of accuracy and performance for 
their use case, organizations must evaluate models and find the best option based on their preferred metrics. Model Evaluation on Amazon Bedrock makes it possible for you to evaluate, compare, and select the best FM for your use case in just a few clicks. In this session, learn how to use the Amazon 
Bedrock automatic and human evaluations, interactive interface, and auto-generated reports to select the right FM for the task.Learn more ab |
| https://www.youtube.com/watch?v=stB-F6jswno | AWS re:Invent 2023 - Scale complete ML development with Amazon SageMaker Studio (AIM325) | Amazon SageMaker Studio offers comprehensive tools for end-to-end ML development—from preparing data to training models, tracking experiments, deploying models, and 
managing pipelines—all in an integrated development environment. To accelerate generative AI development, you need integrated purpose-built tools to train and tune your foundation models (FMs) and a flexible environment to customize your ML workflow. In this session, learn about the latest SageMaker Studio
features to help you quickly build, test, fine-tune, and iterate models to improve productivity and performance. Also hear how  |

